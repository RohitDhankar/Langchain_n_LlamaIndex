_11_02_2024_20:26:05 - DEBUG -_Name: ollama_llm.py -_Meth_Name: <module>() -_Line: 25 -_Log_Message:  ----LOGGING--1--->> <class 'langchain_core.prompts.prompt.PromptTemplate'>
_11_02_2024_20:26:05 - DEBUG -_Name: ollama_llm.py -_Meth_Name: <module>() -_Line: 25 -_Log_Message:  ----LOGGING--1--->> <class 'langchain_core.prompts.prompt.PromptTemplate'>
_11_02_2024_20:26:06 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 39 -_Log_Message:  None
_11_02_2024_20:26:06 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 39 -_Log_Message:  None
_11_02_2024_20:26:06 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 52 -_Log_Message:  --langc_sql_db_name.dialect--->> sqlite
_11_02_2024_20:26:06 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 52 -_Log_Message:  --langc_sql_db_name.dialect--->> sqlite
_11_02_2024_20:26:06 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 54 -_Log_Message:  --langc_sql_db_name.get_usable_table_names()--->> ['mtcars_name_df']
_11_02_2024_20:26:06 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 54 -_Log_Message:  --langc_sql_db_name.get_usable_table_names()--->> ['mtcars_name_df']
_11_02_2024_20:26:06 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_llama_idx_sqldb() -_Line: 76 -_Log_Message:  ---get_llama_idx_sqldb--TYPE-sql_db_llama_idx--->> <class 'llama_index.core.utilities.sql_wrapper.SQLDatabase'>
_11_02_2024_20:26:06 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_llama_idx_sqldb() -_Line: 76 -_Log_Message:  ---get_llama_idx_sqldb--TYPE-sql_db_llama_idx--->> <class 'llama_index.core.utilities.sql_wrapper.SQLDatabase'>
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 36 -_Log_Message:  --EMBEDDING_MODEL->> <class 'str'>
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 36 -_Log_Message:  --EMBEDDING_MODEL->> <class 'str'>
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 36 -_Log_Message:  --EMBEDDING_MODEL->> <class 'str'>
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 36 -_Log_Message:  --EMBEDDING_MODEL->> <class 'str'>
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 36 -_Log_Message:  --EMBEDDING_MODEL->> <class 'str'>
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 36 -_Log_Message:  --EMBEDDING_MODEL->> <class 'str'>
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 41 -_Log_Message:  -init--st.session_state--->> {'sql_alchemy_engine': Engine(sqlite:///mtcars.db), 'dataset_name': 'mtcars', 'sqlite_tb_name': 'mtcars_name_df', 'sqlite_db': <langchain_community.utilities.sql_database.SQLDatabase object at 0x7fb9e75786b0>, 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'list_of_datasets': ['mtcars', 'tips', 'UKgas', 'airquality']}
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 41 -_Log_Message:  -init--st.session_state--->> {'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest']}
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 41 -_Log_Message:  -init--st.session_state--->> {'sql_alchemy_engine': Engine(sqlite:///mtcars.db), 'dataset_name': 'mtcars', 'sqlite_tb_name': 'mtcars_name_df', 'sqlite_db': <langchain_community.utilities.sql_database.SQLDatabase object at 0x7fb9e75786b0>, 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'list_of_datasets': ['mtcars', 'tips', 'UKgas', 'airquality']}
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 51 -_Log_Message:  -init-a-st.session_state--->> {'sql_alchemy_engine': Engine(sqlite:///mtcars.db), 'dataset_name': 'mtcars', 'sqlite_tb_name': 'mtcars_name_df', 'llm': Ollama(model='nomic-embed-text:latest'), 'sqlite_db': <langchain_community.utilities.sql_database.SQLDatabase object at 0x7fb9e75786b0>, 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'ollama_model': 'nomic-embed-text:latest', 'list_of_datasets': ['mtcars', 'tips', 'UKgas', 'airquality']}
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 41 -_Log_Message:  -init--st.session_state--->> {'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest']}
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 51 -_Log_Message:  -init-a-st.session_state--->> {'llm': Ollama(model='nomic-embed-text:latest'), 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'ollama_model': 'nomic-embed-text:latest'}
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 41 -_Log_Message:  -init--st.session_state--->> {'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest']}
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 51 -_Log_Message:  -init-a-st.session_state--->> {'sql_alchemy_engine': Engine(sqlite:///mtcars.db), 'dataset_name': 'mtcars', 'sqlite_tb_name': 'mtcars_name_df', 'llm': Ollama(model='nomic-embed-text:latest'), 'sqlite_db': <langchain_community.utilities.sql_database.SQLDatabase object at 0x7fb9e75786b0>, 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'ollama_model': 'nomic-embed-text:latest', 'list_of_datasets': ['mtcars', 'tips', 'UKgas', 'airquality']}
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 55 -_Log_Message:  -local Docs Loading from Folder Path ->> pdf_dir
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 51 -_Log_Message:  -init-a-st.session_state--->> {'llm': Ollama(model='nomic-embed-text:latest'), 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'ollama_model': 'nomic-embed-text:latest'}
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 41 -_Log_Message:  -init--st.session_state--->> {'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest']}
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 55 -_Log_Message:  -local Docs Loading from Folder Path ->> pdf_dir
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 55 -_Log_Message:  -local Docs Loading from Folder Path ->> pdf_dir
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 55 -_Log_Message:  -local Docs Loading from Folder Path ->> pdf_dir
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 51 -_Log_Message:  -init-a-st.session_state--->> {'llm': Ollama(model='nomic-embed-text:latest'), 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'ollama_model': 'nomic-embed-text:latest'}
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 99 -_Log_Message:  -STARTED-chat_input->>
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 51 -_Log_Message:  -init-a-st.session_state--->> {'llm': Ollama(model='nomic-embed-text:latest'), 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'ollama_model': 'nomic-embed-text:latest'}
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 55 -_Log_Message:  -local Docs Loading from Folder Path ->> pdf_dir
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 99 -_Log_Message:  -STARTED-chat_input->>
_11_02_2024_20:26:06 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 55 -_Log_Message:  -local Docs Loading from Folder Path ->> pdf_dir
_11_02_2024_20:26:07 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 39 -_Log_Message:  None
_11_02_2024_20:26:07 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 39 -_Log_Message:  None
_11_02_2024_20:26:07 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 39 -_Log_Message:  None
_11_02_2024_20:26:07 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 39 -_Log_Message:  None
_11_02_2024_20:26:07 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 52 -_Log_Message:  --langc_sql_db_name.dialect--->> sqlite
_11_02_2024_20:26:07 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 52 -_Log_Message:  --langc_sql_db_name.dialect--->> sqlite
_11_02_2024_20:26:07 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 54 -_Log_Message:  --langc_sql_db_name.get_usable_table_names()--->> ['mtcars_name_df']
_11_02_2024_20:26:07 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 54 -_Log_Message:  --langc_sql_db_name.get_usable_table_names()--->> ['mtcars_name_df']
_11_02_2024_20:26:07 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 96 -_Log_Message:  -init--st.session_state--sqlite_db->> {'sql_alchemy_engine': Engine(sqlite:///mtcars.db), 'dataset_name': 'mtcars', 'sqlite_tb_name': 'mtcars_name_df', 'messages': [], 'llm': Ollama(model='nomic-embed-text:latest'), 'sqlite_db': <langchain_community.utilities.sql_database.SQLDatabase object at 0x7fb9e0854680>, 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'ollama_model': 'nomic-embed-text:latest', 'list_of_datasets': ['mtcars', 'tips', 'UKgas', 'airquality']}
_11_02_2024_20:26:07 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 96 -_Log_Message:  -init--st.session_state--sqlite_db->> {'sql_alchemy_engine': Engine(sqlite:///mtcars.db), 'dataset_name': 'mtcars', 'sqlite_tb_name': 'mtcars_name_df', 'messages': [], 'llm': Ollama(model='nomic-embed-text:latest'), 'sqlite_db': <langchain_community.utilities.sql_database.SQLDatabase object at 0x7fb9e0854680>, 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'ollama_model': 'nomic-embed-text:latest', 'list_of_datasets': ['mtcars', 'tips', 'UKgas', 'airquality']}
_11_02_2024_20:26:07 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 99 -_Log_Message:  -STARTED-chat_input->>
_11_02_2024_20:26:07 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 99 -_Log_Message:  -STARTED-chat_input->>
_11_02_2024_20:26:07 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 52 -_Log_Message:  --langc_sql_db_name.dialect--->> sqlite
_11_02_2024_20:26:07 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 52 -_Log_Message:  --langc_sql_db_name.dialect--->> sqlite
_11_02_2024_20:26:07 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 54 -_Log_Message:  --langc_sql_db_name.get_usable_table_names()--->> ['mtcars_name_df']
_11_02_2024_20:26:07 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 54 -_Log_Message:  --langc_sql_db_name.get_usable_table_names()--->> ['mtcars_name_df']
_11_02_2024_20:26:07 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 96 -_Log_Message:  -init--st.session_state--sqlite_db->> {'sql_alchemy_engine': Engine(sqlite:///mtcars.db), 'dataset_name': 'mtcars', 'sqlite_tb_name': 'mtcars_name_df', 'messages': [], 'llm': Ollama(model='nomic-embed-text:latest'), 'sqlite_db': <langchain_community.utilities.sql_database.SQLDatabase object at 0x7fb9e0856210>, 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'ollama_model': 'nomic-embed-text:latest', 'list_of_datasets': ['mtcars', 'tips', 'UKgas', 'airquality']}
_11_02_2024_20:26:07 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 96 -_Log_Message:  -init--st.session_state--sqlite_db->> {'sql_alchemy_engine': Engine(sqlite:///mtcars.db), 'dataset_name': 'mtcars', 'sqlite_tb_name': 'mtcars_name_df', 'messages': [], 'llm': Ollama(model='nomic-embed-text:latest'), 'sqlite_db': <langchain_community.utilities.sql_database.SQLDatabase object at 0x7fb9e0856210>, 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'ollama_model': 'nomic-embed-text:latest', 'list_of_datasets': ['mtcars', 'tips', 'UKgas', 'airquality']}
_11_02_2024_20:26:07 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 99 -_Log_Message:  -STARTED-chat_input->>
_11_02_2024_20:26:07 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 99 -_Log_Message:  -STARTED-chat_input->>
_11_02_2024_20:26:22 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 36 -_Log_Message:  --EMBEDDING_MODEL->> <class 'str'>
_11_02_2024_20:26:22 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 36 -_Log_Message:  --EMBEDDING_MODEL->> <class 'str'>
_11_02_2024_20:26:22 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 51 -_Log_Message:  -init-a-st.session_state--->> {'sql_alchemy_engine': Engine(sqlite:///mtcars.db), 'dataset_name': 'mtcars', 'sqlite_db': <langchain_community.utilities.sql_database.SQLDatabase object at 0x7fb9e75786b0>, 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'list_of_datasets': ['mtcars', 'tips', 'UKgas', 'airquality'], 'sqlite_tb_name': 'mtcars_name_df', 'messages': [], 'llm': Ollama(model='nomic-embed-text:latest'), 'ollama_model': 'nomic-embed-text:latest'}
_11_02_2024_20:26:22 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 51 -_Log_Message:  -init-a-st.session_state--->> {'sql_alchemy_engine': Engine(sqlite:///mtcars.db), 'dataset_name': 'mtcars', 'sqlite_db': <langchain_community.utilities.sql_database.SQLDatabase object at 0x7fb9e75786b0>, 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'list_of_datasets': ['mtcars', 'tips', 'UKgas', 'airquality'], 'sqlite_tb_name': 'mtcars_name_df', 'messages': [], 'llm': Ollama(model='nomic-embed-text:latest'), 'ollama_model': 'nomic-embed-text:latest'}
_11_02_2024_20:26:22 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 55 -_Log_Message:  -local Docs Loading from Folder Path ->> pdf_dir
_11_02_2024_20:26:22 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 55 -_Log_Message:  -local Docs Loading from Folder Path ->> pdf_dir
_11_02_2024_20:26:22 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 99 -_Log_Message:  -STARTED-chat_input->>
_11_02_2024_20:26:22 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 99 -_Log_Message:  -STARTED-chat_input->>
_11_02_2024_20:26:32 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 36 -_Log_Message:  --EMBEDDING_MODEL->> <class 'str'>
_11_02_2024_20:26:32 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 36 -_Log_Message:  --EMBEDDING_MODEL->> <class 'str'>
_11_02_2024_20:26:32 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 51 -_Log_Message:  -init-a-st.session_state--->> {'sql_alchemy_engine': Engine(sqlite:///mtcars.db), 'dataset_name': 'mtcars', 'sqlite_db': <langchain_community.utilities.sql_database.SQLDatabase object at 0x7fb9e75786b0>, 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'list_of_datasets': ['mtcars', 'tips', 'UKgas', 'airquality'], 'sqlite_tb_name': 'mtcars_name_df', 'messages': [], 'llm': Ollama(model='nomic-embed-text:latest'), 'ollama_model': 'nomic-embed-text:latest'}
_11_02_2024_20:26:32 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 51 -_Log_Message:  -init-a-st.session_state--->> {'sql_alchemy_engine': Engine(sqlite:///mtcars.db), 'dataset_name': 'mtcars', 'sqlite_db': <langchain_community.utilities.sql_database.SQLDatabase object at 0x7fb9e75786b0>, 'list_of_models': ['nomic-embed-text:latest', 'llama3.1:latest', 'llama3.2:latest', 'mistral:latest'], 'list_of_datasets': ['mtcars', 'tips', 'UKgas', 'airquality'], 'sqlite_tb_name': 'mtcars_name_df', 'messages': [], 'llm': Ollama(model='nomic-embed-text:latest'), 'ollama_model': 'nomic-embed-text:latest'}
_11_02_2024_20:26:32 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 55 -_Log_Message:  -local Docs Loading from Folder Path ->> pdf_dir
_11_02_2024_20:26:32 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 55 -_Log_Message:  -local Docs Loading from Folder Path ->> pdf_dir
_11_02_2024_20:26:32 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 99 -_Log_Message:  -STARTED-chat_input->>
_11_02_2024_20:26:32 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 99 -_Log_Message:  -STARTED-chat_input->>
_11_02_2024_20:26:32 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_llama_idx_sqldb() -_Line: 76 -_Log_Message:  ---get_llama_idx_sqldb--TYPE-sql_db_llama_idx--->> <class 'llama_index.core.utilities.sql_wrapper.SQLDatabase'>
_11_02_2024_20:26:32 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_llama_idx_sqldb() -_Line: 76 -_Log_Message:  ---get_llama_idx_sqldb--TYPE-sql_db_llama_idx--->> <class 'llama_index.core.utilities.sql_wrapper.SQLDatabase'>
_11_02_2024_20:26:32 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 116 -_Log_Message:  ---get_llama_idx_sqldb--TYPE-sql_db_llama_idx--aa->> <class 'llama_index.core.utilities.sql_wrapper.SQLDatabase'>
_11_02_2024_20:26:32 - DEBUG -_Name: ui.py -_Meth_Name: <module>() -_Line: 116 -_Log_Message:  ---get_llama_idx_sqldb--TYPE-sql_db_llama_idx--aa->> <class 'llama_index.core.utilities.sql_wrapper.SQLDatabase'>
_11_02_2024_20:26:32 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 107 -_Log_Message:  --ls_table_schema_objs--->> [SQLTableSchema(table_name='mtcars_name_df', context_str=None)]
_11_02_2024_20:26:32 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 107 -_Log_Message:  --ls_table_schema_objs--->> [SQLTableSchema(table_name='mtcars_name_df', context_str=None)]
_11_02_2024_20:26:33 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 114 -_Log_Message:  --obj_index--->> <llama_index.core.objects.base.ObjectIndex object at 0x7fb9e1194680>
_11_02_2024_20:26:33 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 114 -_Log_Message:  --obj_index--->> <llama_index.core.objects.base.ObjectIndex object at 0x7fb9e1194680>
_11_02_2024_20:26:33 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 116 -_Log_Message:  --obj_retriever--->> <llama_index.core.objects.base.ObjectRetriever object at 0x7fb9d8fa7e00>
_11_02_2024_20:26:33 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 116 -_Log_Message:  --obj_retriever--->> <llama_index.core.objects.base.ObjectRetriever object at 0x7fb9d8fa7e00>
_11_02_2024_20:26:33 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 120 -_Log_Message:  --sql_tab_retr_query_engine--->> <llama_index.core.indices.struct_store.sql_query.SQLTableRetrieverQueryEngine object at 0x7fb9d8fa7fe0>
_11_02_2024_20:26:33 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 120 -_Log_Message:  --sql_tab_retr_query_engine--->> <llama_index.core.indices.struct_store.sql_query.SQLTableRetrieverQueryEngine object at 0x7fb9d8fa7fe0>
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 123 -_Log_Message:  --response_sql_retr_eng--->> It appears that there's an error in your SQL query. The column name 'Unnamed' doesn't exist in the table 'mtcars_name_df'. 

The correct query should be:

```sql
SELECT COUNT(*) 
FROM mtcars_name_df;
```

In this corrected query, we're using `COUNT(*)` instead of `COUNT(Unnamed)`, which counts all rows in the table and returns the total number of cars.
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 123 -_Log_Message:  --response_sql_retr_eng--->> It appears that there's an error in your SQL query. The column name 'Unnamed' doesn't exist in the table 'mtcars_name_df'. 

The correct query should be:

```sql
SELECT COUNT(*) 
FROM mtcars_name_df;
```

In this corrected query, we're using `COUNT(*)` instead of `COUNT(Unnamed)`, which counts all rows in the table and returns the total number of cars.
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 128 -_Log_Message:  --res_sql_retr_eng--->> It appears that there's an error in your SQL query. The column name 'Unnamed' doesn't exist in the table 'mtcars_name_df'. 

The correct query should be:

```sql
SELECT COUNT(*) 
FROM mtcars_name_df;
```

In this corrected query, we're using `COUNT(*)` instead of `COUNT(Unnamed)`, which counts all rows in the table and returns the total number of cars.
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 128 -_Log_Message:  --res_sql_retr_eng--->> It appears that there's an error in your SQL query. The column name 'Unnamed' doesn't exist in the table 'mtcars_name_df'. 

The correct query should be:

```sql
SELECT COUNT(*) 
FROM mtcars_name_df;
```

In this corrected query, we're using `COUNT(*)` instead of `COUNT(Unnamed)`, which counts all rows in the table and returns the total number of cars.
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 129 -_Log_Message:  --res_source_nodes--->> [NodeWithScore(node=TextNode(id_='ab7ec60d-c7f7-4482-af90-b68a6628cd6a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text="Error: Statement 'SELECT COUNT(Unnamed) FROM mtcars_name_df' is invalid SQL.", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), score=None)]
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 129 -_Log_Message:  --res_source_nodes--->> [NodeWithScore(node=TextNode(id_='ab7ec60d-c7f7-4482-af90-b68a6628cd6a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text="Error: Statement 'SELECT COUNT(Unnamed) FROM mtcars_name_df' is invalid SQL.", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), score=None)]
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 150 -_Log_Message:  --TYPE--sql_retriever--->> <class 'llama_index.core.indices.struct_store.sql_retriever.SQLRetriever'>
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 150 -_Log_Message:  --TYPE--sql_retriever--->> <class 'llama_index.core.indices.struct_store.sql_retriever.SQLRetriever'>
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 151 -_Log_Message:  --sql_retriever--->> <llama_index.core.indices.struct_store.sql_retriever.SQLRetriever object at 0x7fb9e1327080>
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 151 -_Log_Message:  --sql_retriever--->> <llama_index.core.indices.struct_store.sql_retriever.SQLRetriever object at 0x7fb9e1327080>
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 154 -_Log_Message:  --TYPE--table_parser_component--->> <class 'llama_index.core.query_pipeline.components.function.FnComponent'>
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 154 -_Log_Message:  --TYPE--table_parser_component--->> <class 'llama_index.core.query_pipeline.components.function.FnComponent'>
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 156 -_Log_Message:  --TYPE--sql_parser_component--->> <class 'llama_index.core.query_pipeline.components.function.FnComponent'>
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 156 -_Log_Message:  --TYPE--sql_parser_component--->> <class 'llama_index.core.query_pipeline.components.function.FnComponent'>
_11_02_2024_20:26:41 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 39 -_Log_Message:  None
_11_02_2024_20:26:41 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 39 -_Log_Message:  None
_11_02_2024_20:26:41 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 52 -_Log_Message:  --langc_sql_db_name.dialect--->> sqlite
_11_02_2024_20:26:41 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 52 -_Log_Message:  --langc_sql_db_name.dialect--->> sqlite
_11_02_2024_20:26:41 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 54 -_Log_Message:  --langc_sql_db_name.get_usable_table_names()--->> ['mtcars_name_df']
_11_02_2024_20:26:41 - DEBUG -_Name: data_ingest.py -_Meth_Name: get_alchemy_engine() -_Line: 54 -_Log_Message:  --langc_sql_db_name.get_usable_table_names()--->> ['mtcars_name_df']
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 167 -_Log_Message:  --text2sql_prompt.template--->> Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return the most interesting examples in the database.

Never query for all the columns from a specific table, only ask for a few relevant columns given the question.

Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Pay attention to which column is in which table. Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:

Question: Question here
SQLQuery: SQL Query to run
SQLResult: Result of the SQLQuery
Answer: Final answer here

Only use tables listed below.
{schema}

Question: {query_str}
SQLQuery: 
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 167 -_Log_Message:  --text2sql_prompt.template--->> Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return the most interesting examples in the database.

Never query for all the columns from a specific table, only ask for a few relevant columns given the question.

Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Pay attention to which column is in which table. Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:

Question: Question here
SQLQuery: SQL Query to run
SQLResult: Result of the SQLQuery
Answer: Final answer here

Only use tables listed below.
{schema}

Question: {query_str}
SQLQuery: 
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 188 -_Log_Message:  ----TYPE-query_pipeline----->> <class 'llama_index.core.query_pipeline.query.QueryPipeline'>
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 188 -_Log_Message:  ----TYPE-query_pipeline----->> <class 'llama_index.core.query_pipeline.query.QueryPipeline'>
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 189 -_Log_Message:  ----TYPE-query_pipeline----->> partial_dict={} callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7fb9e0698500> module_dict={'input': InputComponent(partial_dict={}), 'table_retriever': ObjectRetrieverComponent(partial_dict={}, retriever=<llama_index.core.objects.base.ObjectRetriever object at 0x7fb9d8fa7e00>), 'table_output_parser': FnComponent(partial_dict={}, fn=<function get_table_context_str at 0x7fb9e07ca3e0>, async_fn=None, output_key='output'), 'text2sql_prompt': PromptComponent(partial_dict={}, prompt=PromptTemplate(metadata={'prompt_type': <PromptType.TEXT_TO_SQL: 'text_to_sql'>}, template_vars=['dialect', 'schema', 'query_str'], kwargs={'dialect': 'sqlite'}, output_parser=None, template_var_mappings=None, function_mappings=None, template='Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return the most interesting examples in the database.\n\nNever query for all the columns from a specific table, only ask for a few relevant columns given the question.\n\nPay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Pay attention to which column is in which table. Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n\nQuestion: Question here\nSQLQuery: SQL Query to run\nSQLResult: Result of the SQLQuery\nAnswer: Final answer here\n\nOnly use tables listed below.\n{schema}\n\nQuestion: {query_str}\nSQLQuery: '), llm=None, format_messages=False), 'text2sql_llm': LLMChatComponent(partial_dict={}, llm=Ollama(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7fba180f3e60>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x7fb9e3154400>, completion_to_prompt=<function default_completion_to_prompt at 0x7fb9e30660c0>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, base_url='http://localhost:11434', model='llama3.2', temperature=0.75, context_window=3900, request_timeout=120.0, prompt_key='prompt', json_mode=False, additional_kwargs={}, is_function_calling_model=True, keep_alive=None), streaming=False), 'sql_output_parser': FnComponent(partial_dict={}, fn=<function parse_response_to_sql at 0x7fb9e16f8360>, async_fn=None, output_key='output'), 'sql_retriever': RetrieverComponent(partial_dict={}, retriever=<llama_index.core.indices.struct_store.sql_retriever.SQLRetriever object at 0x7fb9e1327080>), 'response_synthesis_prompt': PromptComponent(partial_dict={}, prompt=PromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['query_str', 'sql_query', 'context_str'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template='Given an input question, synthesize a response from the query results.\nQuery: {query_str}\nSQL: {sql_query}\nSQL Response: {context_str}\nResponse: '), llm=None, format_messages=False), 'response_synthesis_llm': LLMChatComponent(partial_dict={}, llm=Ollama(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7fba180f3e60>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x7fb9e3154400>, completion_to_prompt=<function default_completion_to_prompt at 0x7fb9e30660c0>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, base_url='http://localhost:11434', model='llama3.2', temperature=0.75, context_window=3900, request_timeout=120.0, prompt_key='prompt', json_mode=False, additional_kwargs={}, is_function_calling_model=True, keep_alive=None), streaming=False)} dag=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fb9d8fa6960> verbose=True show_progress=False num_workers=4 state={}
_11_02_2024_20:26:41 - DEBUG -_Name: invoke_nl2sql_llamaIdx.py -_Meth_Name: wrapper_get_query() -_Line: 189 -_Log_Message:  ----TYPE-query_pipeline----->> partial_dict={} callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7fb9e0698500> module_dict={'input': InputComponent(partial_dict={}), 'table_retriever': ObjectRetrieverComponent(partial_dict={}, retriever=<llama_index.core.objects.base.ObjectRetriever object at 0x7fb9d8fa7e00>), 'table_output_parser': FnComponent(partial_dict={}, fn=<function get_table_context_str at 0x7fb9e07ca3e0>, async_fn=None, output_key='output'), 'text2sql_prompt': PromptComponent(partial_dict={}, prompt=PromptTemplate(metadata={'prompt_type': <PromptType.TEXT_TO_SQL: 'text_to_sql'>}, template_vars=['dialect', 'schema', 'query_str'], kwargs={'dialect': 'sqlite'}, output_parser=None, template_var_mappings=None, function_mappings=None, template='Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return the most interesting examples in the database.\n\nNever query for all the columns from a specific table, only ask for a few relevant columns given the question.\n\nPay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Pay attention to which column is in which table. Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n\nQuestion: Question here\nSQLQuery: SQL Query to run\nSQLResult: Result of the SQLQuery\nAnswer: Final answer here\n\nOnly use tables listed below.\n{schema}\n\nQuestion: {query_str}\nSQLQuery: '), llm=None, format_messages=False), 'text2sql_llm': LLMChatComponent(partial_dict={}, llm=Ollama(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7fba180f3e60>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x7fb9e3154400>, completion_to_prompt=<function default_completion_to_prompt at 0x7fb9e30660c0>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, base_url='http://localhost:11434', model='llama3.2', temperature=0.75, context_window=3900, request_timeout=120.0, prompt_key='prompt', json_mode=False, additional_kwargs={}, is_function_calling_model=True, keep_alive=None), streaming=False), 'sql_output_parser': FnComponent(partial_dict={}, fn=<function parse_response_to_sql at 0x7fb9e16f8360>, async_fn=None, output_key='output'), 'sql_retriever': RetrieverComponent(partial_dict={}, retriever=<llama_index.core.indices.struct_store.sql_retriever.SQLRetriever object at 0x7fb9e1327080>), 'response_synthesis_prompt': PromptComponent(partial_dict={}, prompt=PromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['query_str', 'sql_query', 'context_str'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template='Given an input question, synthesize a response from the query results.\nQuery: {query_str}\nSQL: {sql_query}\nSQL Response: {context_str}\nResponse: '), llm=None, format_messages=False), 'response_synthesis_llm': LLMChatComponent(partial_dict={}, llm=Ollama(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7fba180f3e60>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x7fb9e3154400>, completion_to_prompt=<function default_completion_to_prompt at 0x7fb9e30660c0>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, base_url='http://localhost:11434', model='llama3.2', temperature=0.75, context_window=3900, request_timeout=120.0, prompt_key='prompt', json_mode=False, additional_kwargs={}, is_function_calling_model=True, keep_alive=None), streaming=False)} dag=<networkx.classes.multidigraph.MultiDiGraph object at 0x7fb9d8fa6960> verbose=True show_progress=False num_workers=4 state={}
